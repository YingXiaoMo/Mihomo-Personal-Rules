# 故障排除与修改日志

本文档记录了 smart 内核使用过程中遇到的关键技术问题及其解决方案。如果您在训练或使用模型时遇到异常，请参考以下内容。

## 1. 数据漂移与时效性
**问题描述**: 
网络环境是动态变化的。如果使用过旧的数据进行训练，模型可能会学习到已经过时的网络特征（例如某个 IP 段曾经很快，现在变慢了），导致预测准确率下降。

**解决方案**:
- **15天滑动窗口**: 训练脚本默认配置为仅加载最近 **15天** 的 CSV 数据文件。
- **自动化重训**: 建议配合 GitHub Actions 或 Crontab 每天自动重新训练，以确保模型始终适应最新的网络环境。



## 2. 信息茧房与幸存者偏差
**问题描述**: 
如果仅使用“测速成功”的高速记录进行训练，模型会倾向于认为“所有节点都很快”，从而忽略了连接失败或高延迟的风险。这被称为“幸存者偏差”。

**解决方案**:
- **引入计数特征**: 在特征工程中明确保留 `success` (成功连接次数) 和 `failure` (失败次数) 特征。
- **保留低分样本**: 在数据清洗阶段，不再简单剔除低速节点，而是通过权重调整让模型学习区分“好节点”和“坏节点”。

## 3. 双重压缩
**问题描述**: 
Mihomo 的某些版本在导出 CSV 时，可能已经对 `maxdownloadrate_kb` 等字段进行了对数 (`Log`) 处理。如果训练脚本在预处理阶段再次对这些字段应用 `np.log1p`，会导致数值被过度压缩（例如 50MB/s 变成了极小的值），使得模型无法区分高速和低速节点。

**解决方案**:
- **移除冗余变换**: 最新版本移除了对目标变量的重复 Log 变换。现在脚本会智能识别数据分布，直接利用原始数值或进行适当的归一化，避免双重压缩。

## 4. RobustScaler 配置错误
**问题描述**: 
为了处理 `success`/`failure` 这种具有长尾分布的计数特征，引入了 `RobustScaler`。但在之前的版本中，其参数未能被正确导出到模型文件中，导致 Go 核心无法应用该缩放。

**解决方案**:
- 更新了模型保存逻辑，在 `Model.bin` 的 `[transforms]` 段落中增加了 `robust_type`, `robust_features`, `robust_center`, `robust_scale` 等标准定义，确保 Go 核心能正确执行鲁棒标准化。

## 常见报错

### Q: 训练日志显示 "No CSV data files found"
**A**: 请确保您已将 Mihomo 导出的 `.csv` 文件放置在项目根目录（或通过 `--data_dir` 指定的目录）。如果您使用 GitHub Actions，请检查 `REMOTE` 变量配置的云端路径是否正确。

### Q: 模型评分 (R²) 很低 (< 0.5)
**A**: 
1. **数据量不足**: 尝试积累更多天数的数据（建议至少 5000 条记录）。
2. **特征缺失**: 确保 `.csv` 文件包含必要的列（如 `latency`, `download_mb`, `success` 等）。
3. **环境噪声**: 检查是否存在大量无效或异常的测试数据。

### Q: Go 核心加载模型报错
**A**: 请确保 Mihomo 版本是最新的，以支持最新的 `Model.bin` 格式和特征变换逻辑。
